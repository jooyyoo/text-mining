{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM6ASDZOwTvLO1dV2UgT4od"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5c512f752ddc463199920893bc984c18":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30bee872d6504eefbb5af9a69e01402d","IPY_MODEL_2093ad3f5213428a900cb8f399af0969","IPY_MODEL_b4db4d41085c40ca9d3965dd808e65e1"],"layout":"IPY_MODEL_ebca5bff586e42e390bf1fc0d69572cc"}},"30bee872d6504eefbb5af9a69e01402d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21cdbd91ed494790864f9a61b509d73d","placeholder":"​","style":"IPY_MODEL_d42a173d529848a0ba12e6d44cf8f279","value":"Downloading pytorch_model.bin: 100%"}},"2093ad3f5213428a900cb8f399af0969":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4acf76c9204461faee3bab9f2bd4bbb","max":267967963,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1632ccbe099b41a0a5c5a5f90a1f1f1a","value":267967963}},"b4db4d41085c40ca9d3965dd808e65e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d401967a12141cfb0aefe2faa14fbd1","placeholder":"​","style":"IPY_MODEL_7664e9d3c4a64ff4aa8fbec463f4492f","value":" 268M/268M [00:02&lt;00:00, 122MB/s]"}},"ebca5bff586e42e390bf1fc0d69572cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21cdbd91ed494790864f9a61b509d73d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d42a173d529848a0ba12e6d44cf8f279":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4acf76c9204461faee3bab9f2bd4bbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1632ccbe099b41a0a5c5a5f90a1f1f1a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d401967a12141cfb0aefe2faa14fbd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7664e9d3c4a64ff4aa8fbec463f4492f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wuDrjp4XekfN","executionInfo":{"status":"ok","timestamp":1682162529492,"user_tz":-540,"elapsed":23617,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"e6edb040-0193-4d19-ff06-2cc5014ce81f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"kRGIbMz5cmLP","executionInfo":{"status":"ok","timestamp":1682162554271,"user_tz":-540,"elapsed":16076,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}}},"outputs":[],"source":["from transformers import pipeline"]},{"cell_type":"markdown","source":["문자 토큰화"],"metadata":{"id":"X5hTVeZXiI-J"}},{"cell_type":"code","source":["text = \"Tokenizing text is a core task of NLP.\"\n","tokenized_text = list(text)\n","print(tokenized_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BdN94xedeqYb","executionInfo":{"status":"ok","timestamp":1682166166266,"user_tz":-540,"elapsed":421,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"754b47dd-75f0-4149-c82a-86d7cd468aaa"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['T', 'o', 'k', 'e', 'n', 'i', 'z', 'i', 'n', 'g', ' ', 't', 'e', 'x', 't', ' ', 'i', 's', ' ', 'a', ' ', 'c', 'o', 'r', 'e', ' ', 't', 'a', 's', 'k', ' ', 'o', 'f', ' ', 'N', 'L', 'P', '.']\n"]}]},{"cell_type":"code","source":["token2idx = {ch: idx for idx, ch in enumerate(sorted(set(tokenized_text)))}\n","print(token2idx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jaRpC5Rge-d9","executionInfo":{"status":"ok","timestamp":1682166167991,"user_tz":-540,"elapsed":395,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"8b8cbf72-b989-49a6-a13c-c71ab39d02dc"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["{' ': 0, '.': 1, 'L': 2, 'N': 3, 'P': 4, 'T': 5, 'a': 6, 'c': 7, 'e': 8, 'f': 9, 'g': 10, 'i': 11, 'k': 12, 'n': 13, 'o': 14, 'r': 15, 's': 16, 't': 17, 'x': 18, 'z': 19}\n"]}]},{"cell_type":"code","source":["input_ids = [token2idx[token] for token in tokenized_text] \n","print(input_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M00w44HJfKDL","executionInfo":{"status":"ok","timestamp":1682166169356,"user_tz":-540,"elapsed":424,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"7c4b7e93-d135-44af-daa3-d307997275c4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[5, 14, 12, 8, 13, 11, 19, 11, 13, 10, 0, 17, 8, 18, 17, 0, 11, 16, 0, 6, 0, 7, 14, 15, 8, 0, 17, 6, 16, 12, 0, 14, 9, 0, 3, 2, 4, 1]\n"]}]},{"cell_type":"markdown","source":["원핫벡터 인코딩(one-hot-vector):문자 토큰화 예"],"metadata":{"id":"FW9huXm2h9go"}},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","\n","input_ids = torch.tensor(input_ids)\n","one_hot_encodings = F.one_hot(input_ids, num_classes=len(token2idx))\n","#one hot 함수가 있다\n","one_hot_encodings.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U-qDoEhIhGhg","executionInfo":{"status":"ok","timestamp":1682166170428,"user_tz":-540,"elapsed":9,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"598f35c7-4a1c-4730-f7c6-31189e671984"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([38, 20])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["print(f\"토큰:{tokenized_text[11]}\")\n","print(f\"텐서 인덱스: {input_ids[11]}\")\n","print(f\"원-핫 인코딩: {one_hot_encodings[11]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTfFod8MjEQS","executionInfo":{"status":"ok","timestamp":1682166171903,"user_tz":-540,"elapsed":500,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"8c503155-b465-479f-8c6d-959039e97e28"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["토큰:t\n","텐서 인덱스: 17\n","원-핫 인코딩: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n"]}]},{"cell_type":"markdown","source":["단어 토큰화\n","\n","공백 기준 토큰화(전통적인 NLP 방법)\n","* 구두점, 어간, 어미 정규화 등 확장 가능\n","\n","장점\n","* 학습의 복잡도 감소 : 모델이 문자에서 단어를 학습\n","\n","단점\n","* 토큰~id 사전(어휘 사전)의 크기 문제\n","* 1백만 유니크 단어라면?\n","\n","\n","> 1 백만 유니크 단어를 1000차원의 벡터로 인코딩하는 행렬\n","> 1000M 의 가중치 필요\n","\n","* 어휘사전 구축 시 발견되지 않았던 단어 처리 문제\n","\n","\n","\n"],"metadata":{"id":"IXW2Z3Zz252J"}},{"cell_type":"markdown","source":["부분 토큰화(subword tokenization)"],"metadata":{"id":"6WAb6Yqx8JMB"}},{"cell_type":"markdown","source":["WordPiece 토크나이저\n","\n","* BPE 를 기반으로 하면서 문자열을 결합할 때 확률적인 방식을 사용한다. 즉, 가장 빈번하게 등장하는 문자열만 결합하는 것이 아니라, 조금 더 드물게 등장하는 문자열도 결합할 수 있도록 확률 분포를 이용한다. \n","* [CLS] [SEP] 시퀀스의 시작과 끝을 알림, 소문자로 변환됨, ##izing 앞의 문자열이 공백이 아님을 의미(앞의 토큰과 합쳐져야 함)"],"metadata":{"id":"GFccYVFT5lu7"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","#AutoTokenizer: WordPiece, BPE 등 모델마다 다양한 토그나이저를 일관되게 다룰 수 있는 자동 클래스\n","#로딩된 내용은 로컬 캐시에 저장됨"],"metadata":{"id":"J1fxo_MBjwOo","executionInfo":{"status":"ok","timestamp":1682166175250,"user_tz":-540,"elapsed":702,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["model_ckpt = \"distilbert-base-uncased\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"],"metadata":{"id":"s5cbMBPM5we7","executionInfo":{"status":"ok","timestamp":1682166176955,"user_tz":-540,"elapsed":352,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["#토크나이징\n","#input_ids: 토큰의 고유 정수값들\n","encoded_text = tokenizer(text)\n","print(encoded_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQphvsNo6RuR","executionInfo":{"status":"ok","timestamp":1682166185202,"user_tz":-540,"elapsed":407,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"22f40f20-71cc-4b68-811a-53036059d7f1"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [101, 19204, 6026, 3793, 2003, 1037, 4563, 4708, 1997, 17953, 2361, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"]}]},{"cell_type":"code","source":["#id -> 토큰\n","tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n","print(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F4cvpHMo6bab","executionInfo":{"status":"ok","timestamp":1682166298576,"user_tz":-540,"elapsed":298,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"5c8d5955-2eca-43e0-e9d5-471b15e8dbdb"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["['[CLS]', 'token', '##izing', 'text', 'is', 'a', 'core', 'task', 'of', 'nl', '##p', '.', '[SEP]']\n"]}]},{"cell_type":"code","source":["#토큰->문자열\n","print(tokenizer.convert_tokens_to_string(tokens))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oT-Qgn5K7GGl","executionInfo":{"status":"ok","timestamp":1682166770527,"user_tz":-540,"elapsed":416,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"64ce9aa4-f1c2-4304-f1f1-7bc030bcddab"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] tokenizing text is a core task of nlp. [SEP]\n"]}]},{"cell_type":"code","source":["#어휘 사전 크기\n","tokenizer.vocab_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TwLRghai8-aD","executionInfo":{"status":"ok","timestamp":1682167105531,"user_tz":-540,"elapsed":460,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"09165c02-ae47-406b-fe4b-ca775e09e7c8"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30522"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["최대 컨텍스트\n","\n","자연어 처리에서 하나의 단어나 문장을 처리하기 위해 고려 할 수 있는 이전과 이후의 단어나 문장의 개수를 의미한다\n","\n","최대 컨덱스트의 크기는 매우 중요한 역할을 한다.\n","\n","예를 들어 자연어 생성 모델에서는 이전의 문장을 고려하여 현재 문장을 생성하는 것이 중요하며, 자연어 이해 모델에서는 주어진 문장 내의 단어들 사이의 관계를 파악하기 위해 이전과 이후의 단어를 함께 고려해야 한다.\n","\n","하지만 그렇다고 너무 크게 지정하면 모델의 계산량이 증가하고 학습 시간이 늘어나는 문제가 발생할 수 있다. 따라서, 최대 컨텍스트 크기는 모델의 성능과 계산 효율성 간의 균형을 고려하여 적잘한 크기로 설정하는 것이 좋다"],"metadata":{"id":"yKPsAQjL_wC6"}},{"cell_type":"code","source":["#최대 컨텍스트 크기\n","tokenizer.model_max_length"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9J9URiMl-QAh","executionInfo":{"status":"ok","timestamp":1682167121848,"user_tz":-540,"elapsed":8,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"5bef723d-42dd-4f48-d29b-80ceafb6789f"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["512"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["#모델이 기대하는 입력 필드 이름\n","tokenizer.model_input_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jrdLqPOB-UPn","executionInfo":{"status":"ok","timestamp":1682167133025,"user_tz":-540,"elapsed":348,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"97aeb1ee-01cb-4346-88fd-31a72c288fba"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['input_ids', 'attention_mask']"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["#스페셜 토큰 정보\n","import pandas as pd\n","tokens2ids = list(zip(tokenizer.all_special_tokens, tokenizer.all_special_ids))\n","data = sorted(tokens2ids, key=lambda x:x[-1])\n","df = pd.DataFrame(data, columns=[\"Special Token\",\"Special Token ID\"])\n","df.T"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148},"id":"tRCAxb_j-XA8","executionInfo":{"status":"ok","timestamp":1682167354791,"user_tz":-540,"elapsed":398,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"2d7e53a6-e73f-4b15-8abd-a8f3d209d506"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                      0      1      2      3       4\n","Special Token     [PAD]  [UNK]  [CLS]  [SEP]  [MASK]\n","Special Token ID      0    100    101    102     103"],"text/html":["\n","  <div id=\"df-bbf63ee6-eee8-4793-bb8e-fbfa9b8db862\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Special Token</th>\n","      <td>[PAD]</td>\n","      <td>[UNK]</td>\n","      <td>[CLS]</td>\n","      <td>[SEP]</td>\n","      <td>[MASK]</td>\n","    </tr>\n","    <tr>\n","      <th>Special Token ID</th>\n","      <td>0</td>\n","      <td>100</td>\n","      <td>101</td>\n","      <td>102</td>\n","      <td>103</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbf63ee6-eee8-4793-bb8e-fbfa9b8db862')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bbf63ee6-eee8-4793-bb8e-fbfa9b8db862 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bbf63ee6-eee8-4793-bb8e-fbfa9b8db862');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["[분류 모델: 트랜스포머를 특성추출기로 활용]\n","\n","1. 사전훈련된 모델 로딩\n","2. 마지막 은닉 상태 추출하기\n","3 사이킷런 스타일로 훈련\n","4. 간단한 분류 모델 훈련하기: logistic regression"],"metadata":{"id":"TMgRPT6qI4Tt"}},{"cell_type":"code","source":["from transformers import AutoModel\n","\n","model_ckpt = \"distilbert-base-uncased\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#GPU/CPU 선택 가능\n","model = AutoModel.from_pretrained(model_ckpt).to(device)\n","#주요 기능: 토큰 인코딩 -> 은닉 상태를 반환"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":151,"referenced_widgets":["5c512f752ddc463199920893bc984c18","30bee872d6504eefbb5af9a69e01402d","2093ad3f5213428a900cb8f399af0969","b4db4d41085c40ca9d3965dd808e65e1","ebca5bff586e42e390bf1fc0d69572cc","21cdbd91ed494790864f9a61b509d73d","d42a173d529848a0ba12e6d44cf8f279","e4acf76c9204461faee3bab9f2bd4bbb","1632ccbe099b41a0a5c5a5f90a1f1f1a","5d401967a12141cfb0aefe2faa14fbd1","7664e9d3c4a64ff4aa8fbec463f4492f"]},"id":"j-9Fk_jt_CP7","executionInfo":{"status":"ok","timestamp":1682170222052,"user_tz":-540,"elapsed":4695,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"fb821fa2-5124-4d06-ee5d-9d2f0cf421e7"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c512f752ddc463199920893bc984c18"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["text = \"this is a test\"\n","inputs = tokenizer(text, return_tensors = \"pt\")\n","print(f\"입력 텐서 크기: {inputs['input_ids'].size()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eGpuYk1EJ1Xa","executionInfo":{"status":"ok","timestamp":1682170449857,"user_tz":-540,"elapsed":416,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"f11dc553-b184-4f52-e7b2-84a5c7643e3f"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 텐서 크기: torch.Size([1, 6])\n"]}]},{"cell_type":"code","source":["inputs = {k:v.to(device) for k,v in inputs.items()}\n","with torch.no_grad():\n","  outputs = model(**inputs)\n","  \n","print(outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZt_mBhnK899","executionInfo":{"status":"ok","timestamp":1682170507920,"user_tz":-540,"elapsed":420,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"f08fe8c7-61f3-42b1-8e35-233d92df1353"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["BaseModelOutput(last_hidden_state=tensor([[[-0.1565, -0.1862,  0.0528,  ..., -0.1188,  0.0662,  0.5470],\n","         [-0.3575, -0.6484, -0.0618,  ..., -0.3040,  0.3508,  0.5221],\n","         [-0.2772, -0.4459,  0.1818,  ..., -0.0948, -0.0076,  0.9958],\n","         [-0.2841, -0.3917,  0.3753,  ..., -0.2151, -0.1173,  1.0526],\n","         [ 0.2661, -0.5094, -0.3180,  ..., -0.4203,  0.0144, -0.2149],\n","         [ 0.9441,  0.0112, -0.4714,  ...,  0.1439, -0.7288, -0.1619]]]), hidden_states=None, attentions=None)\n"]}]},{"cell_type":"code","source":["outputs.last_hidden_state.size()\n","#batchsize, token 개수, 토큰의 벡터 길이"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xyq1o3kYLO8k","executionInfo":{"status":"ok","timestamp":1682170536495,"user_tz":-540,"elapsed":418,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"3a3cc7a4-5c8b-4e80-c369-144e5e0039a8"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 6, 768])"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["outputs.last_hidden_state[:,0].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fIFGUXCHLV7X","executionInfo":{"status":"ok","timestamp":1682170682120,"user_tz":-540,"elapsed":408,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"540f729d-bac0-4517-f5fb-b13dc738778d"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 768])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["def extract_hidden_states(batch):\n","  #모델 입력을 GPU로 옮깁니다\n","  inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}\n","  #마지막 은닉 상태를 추출합니다\n","  with torch.no_grad():\n","    last_hidden_state = model(**inputs).last_hidden_state\n","    #[CLS] 토큰에 대한 벡터를 반환한다\n","  return {\"hidden_state\": last_hidden_state[:0].cpu().numpy()}"],"metadata":{"id":"vF2NrK3FL5by","executionInfo":{"status":"ok","timestamp":1682171528338,"user_tz":-540,"elapsed":506,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["  emotions_encoded.set_format(\"torch\",columns=[\"input_ids\",\"attention_mask\",\"label\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":190},"id":"gy9zyH7NOp10","executionInfo":{"status":"error","timestamp":1682171529897,"user_tz":-540,"elapsed":13,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"e9271751-2303-4452-f29f-4a2dd69756dd"},"execution_count":38,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-20dd15b8b61d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memotions_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'emotions_encoded' is not defined"]}]},{"cell_type":"code","source":["emotions_hidden = emotions_encoded.map(extract_hidden_states,batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172},"id":"mmlvaxTxOsy2","executionInfo":{"status":"error","timestamp":1682171422915,"user_tz":-540,"elapsed":405,"user":{"displayName":"Jooyoung Yun","userId":"08346946677369879997"}},"outputId":"a42080b3-9552-4e1b-d3be-eff8bb24fb09"},"execution_count":34,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-468d85cd8eb2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memotions_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memotions_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'emotions_encoded' is not defined"]}]},{"cell_type":"code","source":[" emotions_hidden[\"train\"].column_names"],"metadata":{"id":"iFrsWqdbOuVr"},"execution_count":null,"outputs":[]}]}